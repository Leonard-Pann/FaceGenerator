{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import torchvision\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.io.image import ImageReadMode\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device:str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images to (64, 64): 100%|██████████| 251/251 [00:14<00:00, 17.19it/s]\n",
      "Resizing images to (128, 128): 100%|██████████| 251/251 [00:14<00:00, 17.32it/s]\n",
      "Resizing images to (256, 256): 100%|██████████| 251/251 [00:15<00:00, 16.72it/s]\n",
      "Resizing images to (512, 512): 100%|██████████| 251/251 [00:16<00:00, 15.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def resize_images(input_path:str, output_path:str, size:tuple[int, int]) -> None:\n",
    "    if os.path.isdir(output_path):\n",
    "       shutil.rmtree(output_path)\n",
    "\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "    raw_images_path:list[str] = os.listdir(input_path)\n",
    "    trans_resize:torchvision.transforms.Resize = torchvision.transforms.Resize(size, InterpolationMode.BICUBIC, antialias=True)\n",
    "\n",
    "    with tqdm.tqdm(total=len(raw_images_path), desc=f\"Resizing images to ({size[0]}, {size[1]})\") as pbar:\n",
    "        for i, image_local_path in enumerate(raw_images_path):\n",
    "            image_absolute_path:str = os.path.join(input_path, image_local_path)\n",
    "            raw_image:torch.Tensor = torchvision.io.read_image(image_absolute_path, ImageReadMode.RGB).to(device)\n",
    "            output_image:torch.Tensor = trans_resize(raw_image).cpu() \n",
    "            torchvision.io.write_png(output_image, os.path.join(output_path, str(i) + \".png\"), 0)\n",
    "            pbar.update(1)\n",
    "\n",
    "input_path:str = os.path.join(os.getcwd(), \"Dataset\", \"raw\")\n",
    "output_paths:list[str] = [\n",
    "    os.path.join(os.getcwd(), \"Dataset\", \"64x64\"),\n",
    "    os.path.join(os.getcwd(), \"Dataset\", \"128x128\"),\n",
    "    os.path.join(os.getcwd(), \"Dataset\", \"256x256\"),\n",
    "    os.path.join(os.getcwd(), \"Dataset\", \"512x512\")\n",
    "]\n",
    "new_sizes:list[tuple[int, int]] = [\n",
    "    (64, 64),\n",
    "    (128, 128),\n",
    "    (256, 256),\n",
    "    (512, 512),\n",
    "]\n",
    "\n",
    "assert len(output_paths) == len(new_sizes)\n",
    "\n",
    "for i in range(0, len(output_paths)):\n",
    "    resize_images(input_path, output_paths[i], new_sizes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
